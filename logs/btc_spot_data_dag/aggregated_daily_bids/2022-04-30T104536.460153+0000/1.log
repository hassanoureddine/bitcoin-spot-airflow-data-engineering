[2022-04-30 10:45:48,736] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: btc_spot_data_dag.aggregated_daily_bids manual__2022-04-30T10:45:36.460153+00:00 [queued]>
[2022-04-30 10:45:48,752] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: btc_spot_data_dag.aggregated_daily_bids manual__2022-04-30T10:45:36.460153+00:00 [queued]>
[2022-04-30 10:45:48,753] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-30 10:45:48,754] {taskinstance.py:1250} INFO - Starting attempt 1 of 1
[2022-04-30 10:45:48,754] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-30 10:45:48,772] {taskinstance.py:1270} INFO - Executing <Task(BigQueryOperator): aggregated_daily_bids> on 2022-04-30 10:45:36.460153+00:00
[2022-04-30 10:45:48,779] {standard_task_runner.py:52} INFO - Started process 1296 to run task
[2022-04-30 10:45:48,783] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'btc_spot_data_dag', 'aggregated_daily_bids', 'manual__2022-04-30T10:45:36.460153+00:00', '--job-id', '83', '--raw', '--subdir', 'DAGS_FOLDER/my_dag.py', '--cfg-path', '/tmp/tmp0_e3e0_e', '--error-file', '/tmp/tmp13vaex7c']
[2022-04-30 10:45:48,785] {standard_task_runner.py:80} INFO - Job 83: Subtask aggregated_daily_bids
[2022-04-30 10:45:48,867] {logging_mixin.py:109} INFO - Running <TaskInstance: btc_spot_data_dag.aggregated_daily_bids manual__2022-04-30T10:45:36.460153+00:00 [running]> on host cf4e030da5d2
[2022-04-30 10:45:48,953] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=btc_spot_data_dag
AIRFLOW_CTX_TASK_ID=aggregated_daily_bids
AIRFLOW_CTX_EXECUTION_DATE=2022-04-30T10:45:36.460153+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-04-30T10:45:36.460153+00:00
[2022-04-30 10:45:48,954] {bigquery.py:655} INFO - Executing: 
            #legacySql
            select sum(bids.size) from `btcspot.btcspot.bids` as bids group by timestamp;
            
[2022-04-30 10:45:48,967] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/providers/google/cloud/hooks/bigquery.py:2058: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
  "This method is deprecated. Please use `BigQueryHook.insert_job` method.", DeprecationWarning

[2022-04-30 10:45:48,976] {bigquery.py:1554} INFO - Inserting job ***_1651315548976056_c80868dbb00856340a75a5944e923144
[2022-04-30 10:45:49,401] {taskinstance.py:1774} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/operators/bigquery.py", line 681, in execute
    encryption_configuration=self.encryption_configuration,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 2192, in run_query
    job = self.insert_job(configuration=configuration, project_id=self.project_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/common/hooks/base_google.py", line 439, in inner_wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/google/cloud/hooks/bigquery.py", line 1560, in insert_job
    job.result(timeout=timeout, retry=retry)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py", line 1499, in result
    do_get_result()
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py", line 1489, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/base.py", line 728, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/google/api_core/future/polling.py", line 137, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Invalid table name: `btcspot.btcspot.bids`
[Try using standard SQL (https://cloud.google.com/bigquery/docs/reference/standard-sql/enabling-standard-sql)].

Location: US
Job ID: airflow_1651315548976056_c80868dbb00856340a75a5944e923144

[2022-04-30 10:45:49,421] {taskinstance.py:1288} INFO - Marking task as FAILED. dag_id=btc_spot_data_dag, task_id=aggregated_daily_bids, execution_date=20220430T104536, start_date=20220430T104548, end_date=20220430T104549
[2022-04-30 10:45:49,439] {standard_task_runner.py:98} ERROR - Failed to execute job 83 for task aggregated_daily_bids (400 Invalid table name: `btcspot.btcspot.bids`
[Try using standard SQL (https://cloud.google.com/bigquery/docs/reference/standard-sql/enabling-standard-sql)].

Location: US
Job ID: airflow_1651315548976056_c80868dbb00856340a75a5944e923144
; 1296)
[2022-04-30 10:45:49,478] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-04-30 10:45:49,524] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
